<a href="https://so-link.github.io/projects/YaoYiyang/">**Yiyang YAO**</a>

My current research is on Multi-Modal Learning, including Contrastive Language-Image Pretraining (CLIP), Multi-Modal LLMs and Domain Adaptation. I am also interested in 3D Reconstruction and Vision-Language-Action (VLA) models.
