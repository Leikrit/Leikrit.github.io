<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Handwriting Formula Recognition | Jinyi LI </title> <meta name="author" content="Jinyi LI"> <meta name="description" content="An image-to-latex inspired framework, transforming handwriting formula images into LaTeX-based context."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%98%87&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://leikrit.github.io/projects/15_HFR/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Jinyi LI </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/people/">connections</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Handwriting Formula Recognition</h1> <p class="post-description">An image-to-latex inspired framework, transforming handwriting formula images into LaTeX-based context.</p> </header> <article> <p>This project was cooperated with Y.L. Li, S. Yang, Z.Y. Tan and W. Liu.</p> <h3 id="introduction">Introduction</h3> <p>This project aims to solve the problems of recognizing pure LaTeX formulas as well as text-mixed formulas. During the project, we applied <strong>ResNet+Transformers</strong> framework. Additionally, we tried to optimize the hyperparameters and researched on the behavior changes according to these hyperparameters.</p> <h3 id="data-preprocessing--data-loading">Data Preprocessing &amp; Data Loading</h3> <p>Firstly, we tried custom datasets that were consisted of txt files and lst files. However, such method caused a highly redundant step which is reading txt files into the cache memory. For each single data, a file-reading operation was needed.</p> <p>Thus, we changed the datasets’ hierarchy, following the format of image-to-latex framework. The whole datasets were divided into an original dataset (only includes images), a simple lst file that contains all labels and 3 filters, which were formatted as lst files. During the train process, the label file is read into the cache, then the filters will map all the images to its corresponding labels.</p> <h3 id="model">Model</h3> <p>We deployed ResNet+Transformers framework with the structure shown as below:</p> <div class="row justify-content-sm-center"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR2-480.webp 480w,/assets/img/HFR2-800.webp 800w,/assets/img/HFR2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR1-480.webp 480w,/assets/img/HFR1-800.webp 800w,/assets/img/HFR1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1&amp;2. The framework of model. </div> <p>At first, we used the original model structure of the image-to-latex project for training. However, because this project is a mixed recognition of text formulas, the size of the new vocabulary was 4 times that of the original vocabulary after generating the vocabulary, and because the training results were not very satisfactory, there were often redundant output in the prediction results. Based on the experience during training, we speculate that this is also the manifestation of underfitting of the model. However, as the amount of training continued to increase, the performance of the model on the test set decreased, showing signs of fitting. We believe that this is because the neural network determines that the category of words to be output has increased too much, and the learning ability of the original model is insufficient.</p> <p>Therefore, we adjusted the parameters of the model in the configuration file, increasing the number of Decoder sub-layers in Transformers Decoder from 3 to 5, and re-trained the modified model. The final performance of the predicted result of the model has been improved, which may be further improved.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR3-480.webp 480w,/assets/img/HFR3-800.webp 800w,/assets/img/HFR3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR4-480.webp 480w,/assets/img/HFR4-800.webp 800w,/assets/img/HFR4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 3&amp;4. The parameter configuration of our framework. </div> <h3 id="training--fine-tuning">Training &amp; Fine-tuning</h3> <h4 id="new-vocabulory">New Vocabulory</h4> <p>In the initial training of the pure mathematical expression recognition model, we used the original vocabulary of the image-to-latex model for training, but the training results were not satisfactory. The model would output unknown characters or blank characters for the input data, and it was usually unable to learn completely for a long input.</p> <p>In addition to the lack of training of the model due to the insufficient number of epochs at the early stage of training, by re-observing the vocabulary and data set, we found that there are two problems: the original vocabulary of the image-to-latex model is incomplete, and the model cannot accurately learn symbols that do not appear in the vocabulary; And there are still a few Chinese characters in the data set of pure mathematical expressions. So we regenerated a complete vocabulary of numbers, English letters, mathematical symbols, and the Chinese characters that appeared in the dataset. For a dataset of mixed recognition of literal and mathematical expressions, we also regenerate a complete vocabulary.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR5-480.webp 480w,/assets/img/HFR5-800.webp 800w,/assets/img/HFR5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 5. Generating new vocabulory for our tasks. </div> <h4 id="parameter-adjustment">Parameter adjustment</h4> <p>Due to the lack of hardware conditions, mainly due to the limitation of GPU memory size, the GPU cannot load a large batch. Therefore, for the pure mathematical expression recognition model, the batch size is adjusted to 16, and the remaining parameters are trained according to the default parameters of the image-to-latex model. Although the simple reduction of batch size solves the problem of insufficient GPU memory, it also creates new problems:</p> <p>(1) The gradient oscillation is severe, the model converges slowly, and the epoch cannot be fully trained after more times.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR6-480.webp 480w,/assets/img/HFR6-800.webp 800w,/assets/img/HFR6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 6. Train loss on pure LaTeX formula recognition model, Learning rate=0.001. </div> <p>As shown in the figure above, the loss value of the model fluctuates severely, and the loss value of the training set still shows no obvious sign of decreasing after training with two epochs.</p> <p>In this respect, we scaled the learning rate and the batch size in the same proportion according to the linear scaling principle, that is, the learning rate was adjusted to 0.0005. The training results showed that the convergence speed of the model was significantly improved, and the character error rate (CER) of the prediction results for the verification set and the test set was also significantly reduced under the same epoch training.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR7-480.webp 480w,/assets/img/HFR7-800.webp 800w,/assets/img/HFR7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 7. Train loss on pure LaTeX formula recognition model, learning rate=0.0005 and max epoch=15. </div> <div class="row justify-content-sm-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR8-480.webp 480w,/assets/img/HFR8-800.webp 800w,/assets/img/HFR8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR9-480.webp 480w,/assets/img/HFR9-800.webp 800w,/assets/img/HFR9-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 8&amp;9. Validation loss &amp; CER on pure LaTeX formula recognition model, learning rate=0.0005 and max epoch=15. </div> <p>(2) The model cannot output long results due to the limitation of parameter <code class="language-plaintext highlighter-rouge">max_output_len</code>. Since the longest label length in the training set is 300, we increase <code class="language-plaintext highlighter-rouge">max_output_len</code> to 400 to meet the need to learn longer expressions.</p> <p>When training the mixed recognition model of literal and mathematical expressions, we made similar parameter adjustments: the batch size was adjusted to 8, the learning rate was adjusted to 0.0003, and the remaining parameters were the same as the pure LaTeX formula recognition model.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR10-480.webp 480w,/assets/img/HFR10-800.webp 800w,/assets/img/HFR10-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 10. Train loss on text-mixed recognition model, learning rate=0.0003 and max epoch=15. </div> <div class="row justify-content-sm-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR11-480.webp 480w,/assets/img/HFR11-800.webp 800w,/assets/img/HFR11-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HFR12-480.webp 480w,/assets/img/HFR12-800.webp 800w,/assets/img/HFR12-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/HFR12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 11&amp;12. Validation loss &amp; CER on text-mixed recognition model, learning rate=0.0003 and max epoch=15. </div> <h4 id="continuing-training">Continuing Training</h4> <p>By analyzing the changes of the loss value and CER value of the model, both of them still declined relatively steadily at the end of training. Therefore, we guessed that the model had not been fully trained, and it was possible to conduct further training to improve the performance of the model. First, we tried to adjust parameters such as the learning rate, but the performance did not improve significantly, so we considered increasing the number of epochs to further optimize the model. We increase the number of epochs on the basis of the original training of the model, observe the result every two epochs, and stop the training if there are signs of overfitting. This step is quite effective for the improvement of the mixed recognition model of literal and mathematical expressions, but the performance of the pure mathematical expression recognition model is not significantly improved. We believe that this is because the mixed text and mathematical expression recognition model has a larger vocabulary and richer label information, and it needs to iteratively train all the data more times before the model can fully learn.</p> <h3 id="hyperparameter-tuning--results">Hyperparameter-Tuning &amp; Results</h3> <table> <thead> <tr> <th>Model</th> <th>Training epoch</th> <th>Training dataset</th> <th>Testing dataset</th> <th>Number of decoder layers</th> <th>BLEU score</th> <th>Edit Distance score</th> <th>Exact Match score</th> <th>Overall score</th> </tr> </thead> <tbody> <tr> <td>Pure</td> <td>15</td> <td>Pure</td> <td>Pure</td> <td>3</td> <td>87.75</td> <td>72.66</td> <td>75.93</td> <td>78.78</td> </tr> <tr> <td>Pure</td> <td>15</td> <td>Pure</td> <td>Pure</td> <td>5</td> <td>92.26</td> <td>80.06</td> <td>84.58</td> <td><strong>85.64</strong></td> </tr> <tr> <td>Pure</td> <td>19</td> <td>Pure</td> <td>Pure</td> <td>5</td> <td>92.32</td> <td>77.76</td> <td>84.88</td> <td>84.99</td> </tr> <tr> <td>Mixed</td> <td>15</td> <td>Mixed</td> <td>Mixed</td> <td>3</td> <td>90.39</td> <td>80.65</td> <td>73.13</td> <td>81.39</td> </tr> <tr> <td>Mixed</td> <td>21</td> <td>Mixed</td> <td>Mixed</td> <td>5</td> <td><strong>94.73</strong></td> <td><strong>88.34</strong></td> <td>83.91</td> <td><strong>88.99</strong></td> </tr> <tr> <td>Mixed</td> <td>21</td> <td>Mixed</td> <td>Pure</td> <td>5</td> <td>93.90</td> <td>82.46</td> <td>87.21</td> <td>87.86</td> </tr> <tr> <td>Mixed</td> <td>23</td> <td>Pure (Based on 21 Mixed)</td> <td>Pure</td> <td>5</td> <td>93.16</td> <td>77.11</td> <td>85.99</td> <td>85.42</td> </tr> <tr> <td>Mixed</td> <td>25</td> <td>Pure (Based on 21 Mixed)</td> <td>Pure</td> <td>5</td> <td>93.20</td> <td>77.05</td> <td>85.95</td> <td>85.40</td> </tr> <tr> <td>Mixed</td> <td>27</td> <td>Pure (Based on 21 Mixed)</td> <td>Pure</td> <td>5</td> <td>93.20</td> <td>78.23</td> <td>86.08</td> <td>85.84</td> </tr> <tr> <td>Mixed</td> <td>29</td> <td>Pure (Based on 21 Mixed)</td> <td>Pure</td> <td>5</td> <td>92.95</td> <td>79.97</td> <td><strong>87.44</strong></td> <td>87.12</td> </tr> <tr> <td>Mixed</td> <td>29</td> <td>Pure (Based on 21 Mixed)</td> <td>Mixed</td> <td>5</td> <td>94.65</td> <td>87.41</td> <td>83.64</td> <td>88.57</td> </tr> </tbody> </table> <p>From the results in the table above, we find that the number of decoder layers has a great impact on the model recognition accuracy. Because of the wide variety and length of the identification formula, a deeper decoder can improve the recognition accuracy. At the same time, we observed the phenomenon of overfitting and underfitting in the model. In the pure mathematical expression recognition model, the recognition accuracy of the model with 15 epochs is higher than that with 19 epochs, and the model overfits on this data set. In the mixed recognition model of text and mathematical expressions, we tried to replace the data set for further training. For example, the model with 23 to 29 epoches showed a basinlike fluctuation in model recognition accuracy, and the recognition rate of the model with 29 epoches decreased compared with that with 21 epoches. We believe that the model has not yet learned the features of the new data set. The recognition rate decreases.</p> <p>Among the above results:</p> <ol> <li> <p>The optimal result of the pure mathematical expression recognition model appears at epoch 15. The loss value of the verification set is about 0.07, and the CER value of the test set reaches 0.023.</p> </li> <li> <p>The optimal result of the hybrid recognition model of literal and mathematical expressions appears at epoch 21. The loss value of the verification set is about 0.07 and the CER value of the test set reaches 0.025.</p> </li> <li> <p>We use the above two optimal models to generate prediction results on the test data identified by pure mathematical expressions and the test data identified by mixed text and mathematical expressions respectively. In addition, since the mixed text and mathematical expression recognition task logically includes the pure mathematical expression recognition task, we try to use the mixed text and mathematical expression recognition model to generate the prediction results of the test data of pure mathematical expression recognition. The scores of each evaluation index are summarized in the following table</p> </li> </ol> <table> <thead> <tr> <th>Model</th> <th>Testing dataset</th> <th>BLEU score</th> <th>Edit Distance score</th> <th>Exact Match score</th> <th>Overall score</th> </tr> </thead> <tbody> <tr> <td>Pure</td> <td>Pure</td> <td>92.26</td> <td>80.06</td> <td>84.58</td> <td>85.64</td> </tr> <tr> <td>Mixed</td> <td>Mixed</td> <td><strong>94.73</strong></td> <td><strong>88.34</strong></td> <td>83.91</td> <td><strong>88.99</strong></td> </tr> <tr> <td>Mixed</td> <td>Pure</td> <td>92.95</td> <td>79.97</td> <td><strong>87.44</strong></td> <td>87.12</td> </tr> </tbody> </table> <p>As can be seen from the table above, pure mathematical expressions that use a mixture of text and mathematical expressions to identify model predictions are better at identifying test data results than pure mathematical expressions to identify model predictions. We believe that the reason is that the training data for mixed recognition of text and mathematical expressions includes both samples of pure mathematical expressions and mixed samples of text and mathematical expressions. The training data is more diverse than that of pure mathematical expressions, and the model can learn richer information after full training. Therefore, no matter the input of mixed text and mathematical expressions, the model can learn more information. Or the input of pure mathematical expressions can give better predictions.</p> <h3 id="conclusion">Conclusion</h3> <p>Through this identification task, we have practiced deep learning in many ways. From the selection of model architecture to data preprocessing and data loading, many attempts have been made in the process of training and parameter adjustment. In the process of trying, we also found some characteristics of deep learning, such as underfitting and overfitting. The final model test results are good.</p> <hr> <p>For more information, see the work in our <a href="https://github.com/Leikrit/LMH_Summer_Programme/tree/main/Autoencoder" rel="external nofollow noopener" target="_blank">github repository</a>!</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Jinyi LI. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: August 26, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>